{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#Overview\"></a>\n",
    "# Overview\n",
    "* <a href=\"#Introduction\">Introduction</a>\n",
    "  * <a href=\"#Methods,-function,-data-types,-and-techiniques\">Methods, function, data types, and techiniques</a>\n",
    "    * <a href=\"#Introduced-in-today's-class\">Introduced in today's class</a>\n",
    "    * <a href=\"#Reviewed-from-previous-class\">Reviewed from previous class</a>\n",
    "* <a href=\"#Loading-the-data\">Loading the data</a>\n",
    "  * <a href=\"#Exercise-1:-read-a-CSV-file\">Exercise 1: read a CSV file</a>\n",
    "* <a href=\"#Selecting-and-averaging-subsets-of-data\">Selecting and averaging subsets of data</a>\n",
    "  * <a href=\"#Exercise-2:-using-masks\">Exercise 2: using masks</a>\n",
    "  * <a href=\"#Exercise-3:-using-groupby\">Exercise 3: using groupby</a>\n",
    "  * <a href=\"#Exercise-4:-more-masks\">Exercise 4: more masks</a>\n",
    "  * <a href=\"#Exercise-5:-more-groupby\">Exercise 5: more groupby</a>\n",
    "* <a href=\"#Plotting-the-data\">Plotting the data</a>\n",
    "  * <a href=\"#Exercise-6:-plotting-mean-latency-by-condition\">Exercise 6: plotting mean latency by condition</a>\n",
    "  * <a href=\"#Exercise-7:-plotting-mean-latency-by-modality\">Exercise 7: plotting mean latency by modality</a>\n",
    "  * <a href=\"#Exercise-8:-plotting-mean-latency-by-group,-modality-and-condition\">Exercise 8: plotting mean latency by group, modality and condition</a>\n",
    "  * <a href=\"#Exercise-9:-plotting-percent-correct-by-group,-modality-and-condition\">Exercise 9: plotting percent correct by group, modality and condition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Introduction\"></a>\n",
    "# Introduction\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "**Analysis of a Behavioral Working Memory Task: the N-Back**\n",
    "\n",
    "Our project involves data collected from two different participant groups: those who have auditory processing problems following head injuries and non-head-injured control participants.\n",
    "\n",
    "The data we’re working with this week involves a common cognitive working memory task called the N-Back.  In our version of the task, participants listen to strings of syllables and must decide whether the current stimulus matches the one displayed n trials ago, where n is a variable number that can be adjusted up or down to respectively increase or decrease cognitive load.  Our experimental conditions include a 0-Back, 1-Back, and 2-Back.  For the 0-Back, the participant only has to remember the first syllable they heard, and they press a button as soon as they hear it again:\n",
    "![N-0 Back](ZeroBack.jpg)\n",
    "\n",
    "For the 1-Back condition, the participant presses the button when the syllable that they hear matches the syllables that was just presented in the previous trial (e.g. pairs of the same syllable):\n",
    "![N-1 Back](OneBack.jpg)\n",
    "\n",
    "Finally, for the 2-Back condition, participants press the button when the syllable they hear matches the syllable they heard two syllables ago (e.g. syllable “sandwiches”):\n",
    "![N2-Back](TwoBack.jpg)\n",
    "\n",
    "So, as you can imagine, the task becomes harder as the value of N is increased and participants have to hold more syllables in working memory.  We are presenting stimuli in both visual and auditory modalities, and thus we have a total of 6 different stimulus conditions (0-, 1-, and 2-Back conditions in visual and auditory modalities), and are measuring how well participants are able to perform the task in each condition (measured as percent of correct button presses in response to target stimuli) as well as the latency of their responses.  Because this is a cognitively demanding task, each condition is measured during three separate runs in order to give folks frequent breaks.  \n",
    "\n",
    "The basic questions we are trying to answer are as follows:\n",
    "- Do participants show the expected reduction in accuracy and increase in latency with increasing n?\n",
    "- Is there a difference in performance accuracy or speed according to sensory modality?\n",
    "- Is there a difference in accuracy and speed between participant groups? For example, do participants with auditory processing problems demonstrate more trouble with the auditory modality than the visual modality?\n",
    "\n",
    "\n",
    "**We can use Python to help us analyze the data to answer these questions!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Methods,-function,-data-types,-and-techiniques\"></a>\n",
    "## Methods, function, data types, and techiniques\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "<a name=\"#Introduced-in-today's-class\"></a>\n",
    "### Introduced in today's class\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "* `basename` - Given a file path (e.g., `Documents/data/filename.csv`, return only the filename (e.g., `filename.csv`);\n",
    "* `append()` - add items to a list;\n",
    "* `glob()` - grabs file names can makes them into a list;\n",
    "* `concat()` - concatinate lists into a dataframe;\n",
    "* `split()` - split a string;\n",
    "* `head()` - a convenient way to print out the top rows of a dataframe;\n",
    "* `dtypes()` - get and set data types;\n",
    "* `astype()` - specify a new data type (e.g., integer, string, etc.);\n",
    "* `replace()` - replace certain items in your list or dataframe;\n",
    "* `head()` - show only the top portion of your dataframe contents;\n",
    "* `yerr` - to add error bars to plots on the y axis;\n",
    "* `legend()` - work with the legend for your plots;\n",
    "* `sem()` - to calculate the standard error of the mean\n",
    "* `plt.ylabel()` - a function in the matplotlib library that allows you to specify the y axis label\n",
    "* `set_ylabel()` - an alternate method for specifying the y-axis label\n",
    "* masks - a technique for pulling out only specific data from your dataframe and making it into its own dataframe;\n",
    "* boolean values - True/False values and how to use them;\n",
    "* for loops - making iterations easy!\n",
    "\n",
    "<a name=\"#Reviewed-from-previous-class\"></a>\n",
    "### Reviewed from previous class\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "* `read_csv()`;\n",
    "* `loc()`;\n",
    "* `groupby()`;\n",
    "* `mean()`;\n",
    "* `plot()`;\n",
    "* `unstack()`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Loading-the-data\"></a>\n",
    "# Loading the data\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Let's import some libraries to help us work with the data.  Run the following cell to import the libraries specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os.path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data are stored as comma-separated values (CSV) files.  First, it's important to know what the data look like in the CSV files so that we know what we're working with. Here's a screen shot of the first file in our list:\n",
    "![First CSV file in our list](csv_file_pic.jpg)\n",
    "\n",
    "The first line is our header, which includes the column names (i.e., trial number, response, type, correct, latency, and stim/response). Awesome! Since it's formatted so nicely, we can just use `pd.read_csv()` like we learned last week to read the files into a dataframe.\n",
    "\n",
    "<a name=\"#Exercise-1:-read-a-CSV-file\"></a>\n",
    "## Exercise 1: read a CSV file\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Just to refresh our memories from last week, go ahead and read in the first data file `data/1001_Aud_N0-Back_run1.csv` as a dataframe and print it. \n",
    "\n",
    "One nice feature about Jupyter Notebooks is that the output of the last line is always displayed below the cell. By default, if you put a variable name by itself on the last line, Jupyter Notebook will display a nicely-formatted representation of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_001.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!  But we seem to have two problems here.  First, the dataframe we've created doesn't have a lot of important information about the file that is contained in the filename including the subject ID, testing modality, N-back condition, and run number. Second, we have a lot of data files here, and it would be tedious to try to read them all in separately.\n",
    "\n",
    "Let's tackle the first problem. How can we parse the information stored in the filename? The format of the filename is:\n",
    "\n",
    "    subject_modality_condition_run.csv\n",
    "    \n",
    "For `1001_Aud_N0-Back_run1.csv`, this gives us:\n",
    "\n",
    "* subject = 1001\n",
    "* modality = Aud\n",
    "* condition = N0-Back\n",
    "* run = run1\n",
    "\n",
    "Since our data is stored in a folder `data`, we need to specify the path to the file relative to the folder the notebook is stored in (i.e., `data/1001_Aud_N0-Back_run1.csv`).\n",
    "\n",
    "We'll use the **`basename`** function (available via the `os.path` module) to get only the filename from the path to the file and the **`split`** method (available on string variables) that splits the string up by a particular character. The important varibales in our filename are conveniently separated by an underscore, so let's this to split the filename. Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathname = 'data/1001_Aud_N0-Back_run1.csv'\n",
    "filename = os.path.basename(pathname)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = filename.split('_')\n",
    "split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!!  Now we have a convenient list that contains each of the variables we need to include in our dataframe.  We can take this one step further and assign names to each of these variables in the following way using a technique known as unpacking. Using this trick, we can take a `list` or `tuple` of N elements and assign the values to the same number of variables on the right hand side of an equation, e.g.:\n",
    "\n",
    "    value = ('A', 'B', 'C')\n",
    "    value1, value2, value3 = value\n",
    "\n",
    "It's a nice, short-hand way of doing the following:\n",
    "\n",
    "    value1 = value[0]\n",
    "    value2 = value[1]\n",
    "    value3 = value[2]\n",
    "    \n",
    "Will the following work?\n",
    "\n",
    "    value = ('A', 'B', 'C')\n",
    "    value1, value2 = value\n",
    "    \n",
    "What about this?\n",
    "\n",
    "    value = ('A', 'B')\n",
    "    value1, value2, value3 = value\n",
    "    \n",
    "And, as a bonus trick question, what do you get?\n",
    "\n",
    "    value = ['A']\n",
    "    value1 = value\n",
    "    \n",
    "What if we do this instead?\n",
    "\n",
    "    value = ['A']\n",
    "    value1, = value\n",
    "    \n",
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject, modality, condition, run  = filename.split('_')\n",
    "condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!!  This also highlights the importance of carefully selecting how you name your datafiles, and also keeping them consistent.  Considering how to format your filename and being consistent in using this format will make it MUCH easier to work with the data.\n",
    "\n",
    "Now let's tackle our second problem which is that we have a lot of data files to read in.  There's an easier way to read them into a dataframe rather than reading them all separately and merging the dataframes. Let's use the **`glob`** function to get a list of all the files we need to read in and combine it with a **`for`** loop to iterate through the list of files. The **`append`** method will save the result of each iteration to a list.\n",
    "\n",
    "Go ahead and run the code below and see what you get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the '*' here tells the glob function to match any character, which will give us all filenames in the\n",
    "# data folder ending in '.csv'\n",
    "glob('data/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = []\n",
    "print(myList)\n",
    "myList.append(1)\n",
    "print(myList)\n",
    "myList.append('one')\n",
    "print(myList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for path in glob('data/*.csv'): \n",
    "    dataset = pd.read_csv(path)\n",
    "    file = os.path.basename(path)\n",
    "    subject, modality, condition, run = file.split('_')\n",
    "    #recall that this syntax is how we assign new columns\n",
    "    dataset['subject'] = subject \n",
    "    dataset['modality'] = modality\n",
    "    dataset['condition'] = condition\n",
    "    dataset['run'] = run\n",
    "    datasets.append(dataset)\n",
    "    \n",
    "# Show only the first three elements in the list\n",
    "datasets[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the upside, we've now got all our data into Python, including columns for subject ID, modality, condition, and run.  \n",
    "\n",
    "But Ugh!! This list of dataframes (one dataframe per file) is not a very accessible way to work with the data.\n",
    "\n",
    "Even though we used the pandas method to read in the datafiles, we read each one into a list that we called *`datasets`*.  So now we just need to use another pandas function **`concat`** to assemble the list of dataframes into one nice single dataframe.  Run the code below and see what you get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.concat(datasets)\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot better!!  But there's one additional thing that could really help us out when we start analyzing this data, and that's adding one more column that specifies the group of each participant.  In this data set, subject IDs in the 1000's indicate control participants while subject ID's in the 2000's indicate the experimental group. So, let's make a new column in our dataframe called 'group' and assign a value based upon whether the subject ID is greater than or less than 2000.  Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['group'] = full_data['subject'] <= 2000\n",
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait! This didn't work! It's because when we called `file.split('_')`, it returned a list of strings. In other words, the subject ID column contains strings, not integers. We're trying to compare a string with an integer, e.g.:\n",
    "\n",
    "    '1013' <= 2000\n",
    "    \n",
    "You can see for yourself by inspecting the `dtypes` attribute on `full_data` which tells you the data type of each column (note that `object` *often* means the column is a string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That won't work. First, we need to convert the subject column from a string to an integer. Fortunately, it's as simple as using the `astype()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subject'] = full_data['subject'].astype('int')\n",
    "full_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['group'] = full_data['subject'] <= 2000\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that our new 'group' column is populated with True and False.  This is because when we use the '<=' operator, we are essentially asking \"is this value less than 2000?\".  It returns \"true\" if the value is less than 2000 and false otherwise. But, it'd be nice to have the group be more meaningful. Let's assign names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename groups\n",
    "full_data['group'] = full_data['group'].replace({True: 'Control', False: 'TBI'})\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Selecting-and-averaging-subsets-of-data\"></a>\n",
    "# Selecting and averaging subsets of data\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "<a name=\"#Exercise-2:-using-masks\"></a>\n",
    "## Exercise 2: using masks\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "This excercise involves extracting the subsetting and extraction of specific parts of this data set that we're particularily interested in. First, we'll want to pull out all trials of type = 10, as this was our target stimulus that we want to analyze responses to.\n",
    "\n",
    "Let's go through an example where we will use a mask approach to filter the data by `Type`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = full_data['Type'] == 10\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a boolean array. Just to refresh our memories, let's look again at our `full_data` dataframe again to see what `types` are included in the first few rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.head()# the head() method is just an easy way to list the first few rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our mask worked. We can see that the first two rows of data, which were *not* type = 10, are coded as `False`, while the third row of data that was type = 10 is correctly coded as `True`. Neat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we acutally get this data in a useable form? \n",
    "\n",
    "Remember the `.loc` attribute from last week?  Here's a little reminder:\n",
    "\n",
    "    value = dataframe.loc[row_label, column_label]\n",
    "\n",
    "`.loc` allows us to extract data of interested. Try to use `.loc` to extract and visualize the data using your `mask`. Lable your new data frame `type_10`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_002.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have a new `dataframe` called 'type_10' with rows that only contain data from our target stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Exercise-3:-using-groupby\"></a>\n",
    "## Exercise 3: using groupby\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's figure out how calculate the percent correct for each participant, modality, and condition. Because the `Correct` column is coded as 0 = Incorrect and 1 = Correct, we can simply take the mean of that whole column to find the average percent correct once we have grouped the data according to participant, modality, and condition.\n",
    "\n",
    "We learned about the `.groupby` method last week. Here's a little reminder:\n",
    "\n",
    "    variable_name = dataframe.groupby(['column_name_1'])\n",
    "    \n",
    "You can specify more than one column name, e.g.:\n",
    "\n",
    "    variable_name = dataframe.groupby(['column_name_1', 'column_name_2', ...])\n",
    "    \n",
    "We can also perform operations on your new data with syntax like this: \n",
    "\n",
    "    variable_name[column_name].mean()\n",
    "\n",
    "We can use a combination of these methods to specify that we want our data grouped by `subject`, `modality`, and `condition` and that we want to take the mean of `Correct` across these columns of interest.\n",
    "\n",
    "Take a stab at setting this up and call your new variable `percent_correct`. Don't forget to multiply the mean by 100 to convert from fraction correct to percent correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_003.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have percent correct data for each subject, modality, and condition.  And this snippet of data seems to indicate that as the task gets harder from the N0-Back condition to the N2-Back condition, performance becomes poorer. Just what we expected - phew!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Exercise-4:-more-masks\"></a>\n",
    "## Exercise 4: more masks\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Having the correct/incorrect information coded as 0s and 1s was really handy for calculating percent correct. But in terms of analyzing the reaction time (latency) of the response, we are only interested in analyzing trials that the participant got correct. Try using a mask and the `.loc` attribute again to subset the data further and extract it in a new variable called `type_10_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_004.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Exercise-5:-more-groupby\"></a>\n",
    "## Exercise 5: more groupby\n",
    "<a href=\"#Overview\">Return to overview</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe that only contains rows of trials that were answered correctly, let's use the `.groupby` method again to calculate average latency across participants, modalities, and conditions. Call your new variable `mean_latency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_005.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Upon first glance, it looks like our average latency data is following a similar trend as our percent correct data: as the condition gets more difficult, the reaction times become longer. But wouldn't it be easier to compare if we plotted it?...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Plotting-the-data\"></a>\n",
    "# Plotting the data\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "<a name=\"#Exercise-6:-plotting-mean-latency-by-condition\"></a>\n",
    "## Exercise 6: plotting mean latency by condition\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Remember our original research questions:\n",
    "- Do participants show the expected reduction in accuracy and increase in latency with increasing n?\n",
    "- Is there a difference in performance accuracy or speed according to sensory modality?\n",
    "- Is there a difference in accuracy and speed between participant groups, especially for auditory versus visual modalities?\n",
    "\n",
    "Let's look at the latency data first.  Recall from last week that we can use the .plot() method to make all sorts of figures.  To answer our first question, we want to look at latency as a function of condition.  So, go ahead and calculate the mean latency grouped by condition only, and then plot this information in a bar plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_006.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, it does look like latency to increases as the task gets more difficult!  Yay! But let's add some standard error bars to this figure to see if the difference looks significant across conditions.  \n",
    "\n",
    "Next, find a method to calculate the standard error of the mean latency after grouping by `condition`.  Call this new variable `sem_grouped_latency`, and print the result.<br>\n",
    "\n",
    "**Hint!** recall that you can type \"variable_name.\" and then press **Tab** to figure out what methods are available for that variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_007.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's replot these data but include error bars this time.  Explore your options for `plot` and try to figure out which variable you need to specifiy the error bars, and then plot the result.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_008.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, those are some tiny error bars!  But it looks like we can definitely answer our first question: YES!  Participants do show the expected increase in reaction time with increasing task difficulty.\n",
    "\n",
    "<a name=\"#Exercise-7:-plotting-mean-latency-by-modality\"></a>\n",
    "## Exercise 7: plotting mean latency by modality\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Now, let's apply what we just learned and plot the average latency grouped by modality this time, including error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_009.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!!  This graph answers our second question: YES, these does appear to be a difference between the two modalities such that participants are faster to respond in the visual modality compared to the auditory modality.\n",
    "<br>\n",
    "\n",
    "<a name=\"#Exercise-8:-plotting-mean-latency-by-group,-modality-and-condition\"></a>\n",
    "## Exercise 8: plotting mean latency by group, modality and condition\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Now, to answer our final questions, we need to do some additional grouping.  Here, we want to compare mean latencies across groups, modality and condition.  Let's go ahead and calculated this grouped mean before we get to plotting.  Call the new variable `grouped_latency` and print the result.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_010.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good.  But now that we're grouping by multiple variables, the data are no longer in a format where the `plot` function can just accept the data and know what to do with it.  Rather, we need need to convert the `condition` column into a row.  We learned how to do this last week!  <br>\n",
    "**Hint!**  The method you need has seven letters, starts with a u and ends with a k!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_011.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the data is now in the correct format for plotting.  Now, let's calculate the SEM for these data and again get it into a form that we can use it for plotting just as we did above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_012.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put it all together and plot the average latency grouped by group, condition, and modality including the standard error bars! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_013.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try to move that key out of the way so that we can see our whole figure. This is a little tricky, but here is the code to move the legend.  Spend a little time playing with the various components to see how it changes the location of your figure legend. The key attributes are:\n",
    "\n",
    "* `loc`: The corner of the legend box that's anchored to the coordinates specified by `bbox_to_anchor`.\n",
    "* `bbox_to_anchor`: The axes coordinates of the legend box corner specified by `loc`. Axes coordinates run from 0 (minimum along the X or Y axes) to 1 (maximum along the X or Y axes). So, specifying XY coordinates of X=1.05 and Y=1 positions the corner just outside the axes themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = grouped_latency.unstack('condition').plot(kind='bar', yerr=sem_grouped_latency_unstacked)\n",
    "axes.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!!  Both groups look pretty similar on the easiest N0-back condition.  But it looks like the TBI group is a little slower than the controls for the N1 and N2 back condition in the auditory modality, while they may be a little *faster* than the control group in the hardest condition of the visual task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"#Exercise-9:-plotting-percent-correct-by-group,-modality-and-condition\"></a>\n",
    "## Exercise 9: plotting percent correct by group, modality and condition\n",
    "<a href=\"#Overview\">Return to overview</a>\n",
    "\n",
    "Recall that we're interested in ability to do the test (percent correct) in addition to reaction times.  So, finally, let's make one more plot just like this last one but using percent correct data.  Remember: we want both correct and incorrect responses here - make sure you're using the `type_10` dataframe and plotting the `correct` variable). You can copy/paste the code we used above and change the appropriate column names and variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load \"answers/answer_014.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the groups are fairly comperable on most conditions except for the N2-Back.  For these conditions, in both auditory and visual modalities, it looks like our TBI folks are performing far below the performance of the controls.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
